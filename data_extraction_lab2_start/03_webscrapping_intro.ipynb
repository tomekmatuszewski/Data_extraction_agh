{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping - wprowadzenie\n",
    "\n",
    "Istniejące API serwisów posiadaja ograniczenia bądź dane serwisy w ogóle takich interfejsów nie posiadają. W takich przypadkach można pobierać dane bezpośrednio ze stron HTML wykorzystując ich strukturę. Strony HTML opierają się na tagach oraz klasach arkuszy stylów i te informacje będziemy wykorzystywali.\n",
    "W tym celu potrzebować będziemy parser języka HTML. W Pythonie wykorzystamy bibliotekę ***BeautifulSoup***.  \n",
    "\n",
    "Dokumentację do biblioteki znajdziesz pod adresem https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "Poniżej kod, który ją importuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/tm/anaconda3/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/tm/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install beautifulsoup4 --user\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podstawowe operacje \n",
    "\n",
    "Zobaczmy jak działa biblioteka. Poniżej mamy przykładową stronkę HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniże przykładowy kod, który tworzy odpowiedni parser dla tej strony i szuka pierwszego elementu typu ```<a>```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(soup.find('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcesz wyciągnąć atrybut taga wykorzystaj funkcję ```get()```, zgodnie z poniższym przykładem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sister']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a').get(\"class\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdziesz listę innych przydatnych funkcji z biblioteki.\n",
    "- \n",
    "- ```element.get_text()``` - pobiera zawartość danego taga\n",
    "- ```element.text``` - pobranie zawartości (ciała) elementu\n",
    "- ```element.parent``` - przechodzi do rodzica danego taga\n",
    "- ```element.next_sibling``` - pobieranie kolejnego elementu na tym samym poziomie\n",
    "- ```element['class']``` - pobranie wartości atrybutu danego elementu\n",
    "- ```element.find_all(\"tag_name\")``` - pobiera wszystkie tagi o nazwie tag_name\n",
    "- ```element.find_all(\"tag_name\", class_=\"class1 class2 ...\")``` - znajduje wszystkie tagi o nazwie tag_name i klasach CSS class1, class2\n",
    "- ```element.select('.nazwaKlasyCSS')``` - pobieranie tagów po nazwie klasy CSS\n",
    "- ```element.select('nazwaTaguHTML')``` - pobieranie tagów po nazwie taga\n",
    "- ```element.select('#IDelementu')``` - pobieranie elementów po ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie nr 4\n",
    "\n",
    "Napisz kod, który z powyższego HTMLa pobierze i wypisze etykiety linków wraz z odnośnikami w następującym formacie:\n",
    "```\n",
    "Elsie - http://example.com/elsie\n",
    "Lacie - http://example.com/lacie\n",
    "Tillie - http://example.com/tillie\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsie - http://example.com/elsie\n",
      "Lacie - http://example.com/lacie\n",
      "Tillie - http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "# TO DO zaimplementuj tutaj swoje rozwiązanie\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "print(*[f\"{link.get_text()} - {link.get('href')}\" for link in links], sep=\"\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając powyższą wiedzę możemy teraz spróbować wykorzystać ją do ekstracji danych z prawdziwej strony internetowej. W tym celu połączymy działanie obu bibliotek.\n",
    "\n",
    "Poniższy kod ilustruje przykładowe działanie a więc wejdzie na stronę główną serwisu www.formula1.com, odnalezienie elementu głównego newsa i wyświetlenie jego zawartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two big questions for McLaren in 2022: Can Ricciardo and Norris return their team to glory?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://www.formula1.com\")\n",
    "pageRootElement = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "for header in pageRootElement.select('.f1--title'):\n",
    "    print(header.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie nr 5\n",
    "\n",
    "Napisz kod, który drukuje wszystkie nagłówki ze strony głównej serwisu www.formula1.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2 - empty,\n",
      "h2 - empty,\n",
      "h2 - Editor's Picks,\n",
      "h2 - More news,\n",
      "h3 - FORMULA 1 GULF AIR BAHRAIN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 STC SAUDI ARABIAN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 HEINEKEN AUSTRALIAN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 ROLEX GRAN PREMIO DELL'EMILIA ROMAGNA 2022,\n",
      "h3 - FORMULA 1 MIAMI GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 PIRELLI GRAN PREMIO DE ESPAÃA 2022,\n",
      "h3 - FORMULA 1 GRAND PRIX DE MONACO 2022,\n",
      "h3 - FORMULA 1 AZERBAIJAN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 GRAND PRIX DU CANADA 2022,\n",
      "h3 - FORMULA 1 BRITISH GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 GROSSER PREIS VON ÃSTERREICH 2022,\n",
      "h3 - FORMULA 1 GRAND PRIX DE FRANCE 2022,\n",
      "h3 - FORMULA 1 MAGYAR NAGYDÃJ 2022,\n",
      "h3 - FORMULA 1 ROLEX BELGIAN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 HEINEKEN DUTCH GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 PIRELLI GRAN PREMIO DâITALIA 2022,\n",
      "h3 - FORMULA 1 VTB RUSSIAN GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 SINGAPORE GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 JAPANESE GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 ARAMCO UNITED STATES GRAND PRIX 2022,\n",
      "h3 - FORMULA 1 GRAN PREMIO DE LA CIUDAD DE MÃXICO 2022,\n",
      "h3 - FORMULA 1 GRANDE PRÃMIO DE SÃO PAULO 2022,\n",
      "h3 - FORMULA 1 ETIHAD AIRWAYS ABU DHABI GRAND PRIX 2022,\n",
      "h3 - 2021 STANDINGS,\n",
      "h3 - 2021 STANDINGS,\n",
      "h3 - United Arab Emirates,\n",
      "h2 - Explore F1 topics\n"
     ]
    }
   ],
   "source": [
    "# TO DO zaimplementuj tutaj swoje rozwiązanie\n",
    "import re\n",
    "response = requests.get(\"https://www.formula1.com\").text\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "headers = soup.find_all(re.compile('^h[1-6]$'))\n",
    "print(*[f'{header.name} - {header.get_text().strip()}' if header.get_text().strip() else f'{header.name} - empty' for header in headers], sep=\",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two big questions for McLaren in 2022: Can Ricciardo and Norris return their team to glory?\n",
      "Pirelli say F1 teams happy to continue with fixed tyre allocations for 2022\n",
      "WATCH: AlphaTauriâs Pierre Gasly gets first look at all-new Miami International Autodrome\n",
      "WATCH: 10 moments of brilliance from four-time champion Sebastian Vettel\n",
      "2022 pre-season testing dates in Barcelona and Bahrain confirmed\n",
      "Two big questions for Alpine in 2022: Can Alonso boost his team up the grid?\n",
      "How McLaren became race winners again\n",
      "WATCH: Pirate Seb, seething Sainz and napping Norris â Enjoy the funniest moments from the 2021 season\n",
      "WATCH: Everything you need to know about the new 2022 F1 car\n",
      "DIARY DATES: The 2022 F1 calendar, pre-season testing and car launch schedule\n",
      "WATCH: F1 drivers and presenters react to the 2021 season\n",
      "2022 F1 GRID: All the drivers and teams racing this season\n",
      "Ricciardo calls Monza 2021 win 'biggest moment of my career' \n",
      "Bottas on Hamilton's greatest strength after their 5 years as Mercedes team mates\n",
      "Leclerc reveals his biggest improvement of last season â and anticipates âchallengingâ adaptation to 2022 cars\n",
      "REVEALED: Your 5 favourite races of 2021 â plus extended highlights of the winner\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(\"https://www.formula1.com\")\n",
    "pageRootElement = BeautifulSoup(response.text, 'html.parser')\n",
    "for header in pageRootElement.select('*:is(.f1--title, .f1-cc--caption .f1--s, .f1-cc--caption > .no-margin)'):\n",
    "    print(header.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-2647211d1649>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-2647211d1649>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for header in pageRootElement.select(class=re.compile(\"\\.f1--.*\")):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(\"https://www.formula1.com\")\n",
    "pageRootElement = BeautifulSoup(response.text, 'html.parser')\n",
    "for header in pageRootElement.select(class=re.compile(\"\\.f1--.*\")):\n",
    "    print(header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
